import { NextRequest, NextResponse } from 'next/server';
import { PHASE_EXPORT, PHASE_PRODUCTION_BUILD } from 'next/constants';
import { RateLimiter, getClientIp } from '@/lib/rateLimit';
import { apiKeyManager, parseRateLimitError } from '@/lib/apiKeyRotation';

// Netlify/Vercel ì„œë²„ë¦¬ìŠ¤ í•¨ìˆ˜ íƒ€ì„ì•„ì›ƒ ì„¤ì • (60ì´ˆ)
export const maxDuration = 60;
export const dynamic = 'force-dynamic';

const isStaticExportPhase =
  process.env.NEXT_PHASE === PHASE_EXPORT ||
  process.env.NEXT_PHASE === PHASE_PRODUCTION_BUILD;

// Rate Limiter ì¸ìŠ¤í„´ìŠ¤ ìƒì„± (ë¶„ë‹¹ 20íšŒ ì œí•œ)
const chatRateLimiter = new RateLimiter(20, 60 * 1000);

type UserAttachment = {
  type: 'image' | 'text';
  name: string;
  mimeType?: string;
  dataUrl?: string; // for images
  content?: string; // for text files
};


function extractBase64(dataUrl: string): { mime: string; base64: string } | null {
  try {
    const match = dataUrl.match(/^data:(.*?);base64,(.*)$/);
    if (!match) return null;
    return { mime: match[1], base64: match[2] };
  } catch {
    return null;
  }
}

// DALL-E ì´ë¯¸ì§€ ìƒì„± API í˜¸ì¶œ
async function callDALLE(prompt: string): Promise<string> {
  return apiKeyManager.enqueueRequest('openai', async () => {
    const apiKey = apiKeyManager.getAvailableKey('openai');
    
    if (!apiKey) {
      throw new Error('OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.');
    }

    if (process.env.NODE_ENV !== 'production') {
      console.log('[DALL-E] Generating image with prompt:', prompt);
    }

    const response = await fetch('https://api.openai.com/v1/images/generations', {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${apiKey}`
      },
      body: JSON.stringify({
        model: 'dall-e-3',
        prompt: prompt,
        n: 1,
        size: '1024x1024',
        quality: 'standard'
      })
    });

    if (!response.ok) {
      const errorData = await response.json();
      if (process.env.NODE_ENV !== 'production') {
        console.error('[DALL-E] Error response:', errorData);
      }
      throw new Error(errorData.error?.message || 'DALL-E API ì˜¤ë¥˜');
    }

    const data = await response.json();
    if (process.env.NODE_ENV !== 'production') {
      console.log('[DALL-E] Image generated successfully');
    }

    // ì´ë¯¸ì§€ URL ë°˜í™˜
    return data.data[0].url;
  });
}

// OpenAI API í˜¸ì¶œ (í‚¤ ë¡œí…Œì´ì…˜ ë° í ì‹œìŠ¤í…œ ì§€ì›) - ë¹„ìŠ¤íŠ¸ë¦¬ë° JSON ë¬¸ìì—´ ë°˜í™˜
async function callOpenAI(model: string, messages: any[], userAttachments?: UserAttachment[], persona?: any, languageInstruction?: string): Promise<string> {
  // ì´ë¯¸ì§€ ìƒì„± ëª¨ë¸ì¸ ê²½ìš° DALL-E API ì‚¬ìš©
  if (model === 'gptimage1' || model === 'dalle3') {
    const lastUserMessage = [...messages].reverse().find((m: any) => m.role === 'user');
    const prompt = typeof lastUserMessage?.content === 'string' 
      ? lastUserMessage.content 
      : lastUserMessage?.content?.[0]?.text || 'ì•„ë¦„ë‹¤ìš´ í’ê²½';
    return await callDALLE(prompt);
  }

  const apiKey = apiKeyManager.getAvailableKey('openai');
  if (!apiKey) {
    throw new Error('OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.');
  }

  return await executeOpenAIRequest(model, messages, apiKey, userAttachments, persona, 0, languageInstruction);
}

// OpenAI ì‹¤ì œ ìš”ì²­ ì‹¤í–‰ - JSON ë¬¸ìì—´ ë°˜í™˜
async function executeOpenAIRequest(model: string, messages: any[], apiKey: string, userAttachments?: UserAttachment[], persona?: any, retryCount: number = 0, languageInstruction?: string): Promise<string> {

  const modelMap: { [key: string]: string } = {
    // GPT ì‹œë¦¬ì¦ˆ
    'gpt5': 'gpt-5',
    'gpt51': 'gpt-5.1',
    'gpt52': 'gpt-5.2',
    'gpt4o': 'gpt-4o',
    'gpt41': 'gpt-4.1',
    // OpenAI o ì‹œë¦¬ì¦ˆ
    'o3': 'o3',
    'o3mini': 'o3-mini',
    'o4mini': 'o4-mini',
    // ì½”ë”© ëª¨ë¸
    'gpt5codex': 'gpt-5-codex',
    'gpt51codex': 'gpt-5.1-codex',
    'gpt52codex': 'gpt-5.2-codex',
    // ì´ë¯¸ì§€ ëª¨ë¸
    'gptimage1': 'gpt-image-1',
    'dalle3': 'dall-e-3',
  };

  // If there are image attachments, convert the LAST user message content to a multimodal array
  const transformedMessages = (() => {
    if (!userAttachments?.length) return messages;
    const lastIdx = [...messages].reverse().findIndex((m: any) => m.role === 'user');
    if (lastIdx === -1) return messages;
    const idx = messages.length - 1 - lastIdx;
    const last = messages[idx];
    const parts: any[] = [];
    if (typeof last.content === 'string') {
      parts.push({ type: 'text', text: last.content });
    } else if (Array.isArray(last.content)) {
      parts.push(...last.content);
    }
    userAttachments.forEach(att => {
      if (att.type === 'image' && att.dataUrl) {
        parts.push({ type: 'image_url', image_url: { url: att.dataUrl } });
      } else if (att.type === 'text' && att.content) {
        parts.push({ type: 'text', text: `File (${att.name}):\n${att.content.slice(0, 4000)}` });
      }
    });
    const newMsgs = [...messages];
    newMsgs[idx] = { role: 'user', content: parts };
    return newMsgs;
  })();

  const selectedModel = modelMap[model];
  if (!selectedModel) {
    throw new Error('ëª¨ë¸ ë§¤í•‘ì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. .env.localì˜ ëª¨ë¸ ë³€ìˆ˜ë¥¼ í™•ì¸í•˜ì„¸ìš”.');
  }

  // í˜ë¥´ì†Œë‚˜ ê¸°ë°˜ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ìƒì„±
  const buildPersonaPrompt = (persona: any) => {
    if (!persona) return '';
    
    let prompt = `ë‹¹ì‹ ì€ "${persona.name}"ì…ë‹ˆë‹¤.\n\n`;
    
    if (persona.personality) {
      const p = persona.personality;
      prompt += `ì„±ê²© íŠ¹ì„±:\n`;
      prompt += `- ë§íˆ¬: ${p.tone === 'formal' ? 'ê²©ì‹ìˆëŠ”' : p.tone === 'casual' ? 'ìºì£¼ì–¼í•œ' : p.tone === 'friendly' ? 'ì¹œê·¼í•œ' : p.tone === 'professional' ? 'ì „ë¬¸ì ì¸' : 'ìœ ë¨¸ëŸ¬ìŠ¤í•œ'}\n`;
      prompt += `- ì–¸ì–´ ìŠ¤íƒ€ì¼: ${p.language === 'polite' ? 'ì •ì¤‘í•œ' : p.language === 'casual' ? 'í¸í•œ' : 'ê¸°ìˆ ì ì¸'}\n`;
      prompt += `- ê°ì • í‘œí˜„ ìˆ˜ì¤€: ${p.emotionLevel}/10\n`;
      prompt += `- ì´ëª¨ì§€ ì‚¬ìš©: ${p.emojiUsage ? 'ì ê·¹ ì‚¬ìš©' : 'ì‚¬ìš© ì•ˆ í•¨'}\n`;
      prompt += `- ë‹µë³€ ê¸¸ì´: ${p.responseLength === 'concise' ? 'ê°„ê²°í•˜ê²Œ' : p.responseLength === 'balanced' ? 'ì ë‹¹í•˜ê²Œ' : 'ìƒì„¸í•˜ê²Œ'}\n\n`;
    }
    
    if (persona.expertise && persona.expertise.domains && persona.expertise.domains.length > 0) {
      prompt += `ì „ë¬¸ ë¶„ì•¼: ${persona.expertise.domains.join(', ')}\n`;
      prompt += `ì „ë¬¸ì„± ìˆ˜ì¤€: ${persona.expertise.level === 'beginner' ? 'ì´ˆê¸‰' : persona.expertise.level === 'intermediate' ? 'ì¤‘ê¸‰' : 'ì „ë¬¸ê°€'}\n\n`;
    }
    
    if (persona.speechPatterns) {
      if (persona.speechPatterns.greetings && persona.speechPatterns.greetings.length > 0) {
        prompt += `ì¸ì‚¬ë§ ì˜ˆì‹œ: ${persona.speechPatterns.greetings[0]}\n`;
      }
      if (persona.speechPatterns.catchPhrases && persona.speechPatterns.catchPhrases.length > 0) {
        prompt += `íŠ¹ì§•ì ì¸ í‘œí˜„: ${persona.speechPatterns.catchPhrases.join(', ')}\n`;
      }
    }
    
    prompt += `\nìœ„ íŠ¹ì„±ì„ ë°˜ì˜í•˜ì—¬ ë‹µë³€í•´ì£¼ì„¸ìš”.`;
    return prompt;
  };
  
  // GPT-5/5.1 ë° ì½”ë”© ëª¨ë¸ìš© ì‹œìŠ¤í…œ ë©”ì‹œì§€ ì¶”ê°€
  const isGPT5Series = model === 'gpt5' || model === 'gpt51' || model === 'gpt52';
  const isCodingModel = model === 'codex' || model === 'gpt5codex' || model === 'gpt51codex';
  
  // ëŒ€í™”ì˜ ì²« ë©”ì‹œì§€ì¸ì§€ í™•ì¸ (ì‹œìŠ¤í…œ ë©”ì‹œì§€ ì œì™¸í•˜ê³  ì‚¬ìš©ì ë©”ì‹œì§€ê°€ 1ê°œì¸ ê²½ìš°)
  const isFirstMessage = transformedMessages.filter((m: any) => m.role === 'user').length === 1;
  
  // ì½”ë“œ ë¸”ë¡ ê·œì¹™ (ì²« ë©”ì‹œì§€ì—ë§Œ í¬í•¨)
  const codeBlockRule = isFirstMessage 
    ? '\n\nì½”ë“œë¥¼ ì¶œë ¥í•  ë•ŒëŠ” ë°˜ë“œì‹œ ///ë¡œ ì½”ë“œë¥¼ ë‘˜ëŸ¬ì‹¸ì„¸ìš”.\nì˜ˆì‹œ:\n///\nfunction example() {\n  return "code here";\n}\n///'
    : '';
  
  // ìš”ì•½ ê·œì¹™ (ì²« ë©”ì‹œì§€ì—ë§Œ í¬í•¨)
  const summaryRule = isFirstMessage
    ? '\n\n**ì¤‘ìš”**: ë‹µë³€ ë§ˆì§€ë§‰ì— ìš”ì•½ì„ ì‘ì„±í•˜ì„¸ìš” (ì‚¬ìš©ìì—ê²Œ ë³´ì´ì§€ ì•ŠìŒ):\n~~\nQ: [ì§ˆë¬¸ 5ë‹¨ì–´ ì´ë‚´]\nA: [ë‹µë³€ í•µì‹¬ 10ë‹¨ì–´ ì´ë‚´]\nPrev: [ì´ì „ ë‹µë³€ ìš”ì•½ ë˜ëŠ” None]\n~~'
    : '';
  
  const baseSystemPrompt = isGPT5Series
    ? `ë‹¹ì‹ ì€ ë„ì›€ì´ ë˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ìµœëŒ€í•œ ìƒì„¸í•˜ê³  í¬ê´„ì ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”.\n\nì„œì‹ ê·œì¹™:\n- ì¤‘ìš”í•˜ê±°ë‚˜ ê°•ì¡°í•˜ê³  ì‹¶ì€ ë‚´ìš©: **ê°•ì¡°í•  ë‚´ìš©**\n- ì„¹ì…˜ ì œëª©ì´ë‚˜ ì£¼ìš” ì£¼ì œ: ## ì œëª© ë‚´ìš©${codeBlockRule}${summaryRule}\n\në‹µë³€ì„ êµ¬ì¡°í™”í•  ë•Œ ## ì œëª©ì„ ì ê·¹ í™œìš©í•˜ì„¸ìš”.`
    : isCodingModel
    ? `ë‹¹ì‹ ì€ ì „ë¬¸ í”„ë¡œê·¸ë˜ë° ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. ì½”ë“œ ì‘ì„±, ë””ë²„ê¹…, ìµœì í™”, ì„¤ëª…ì— íŠ¹í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤.\n\nì„œì‹ ê·œì¹™:${codeBlockRule}${summaryRule}\n- ì¤‘ìš”í•œ ë¶€ë¶„: **ê°•ì¡°**\n- ì„¹ì…˜ ì œëª©: ## ì œëª©\n\në‹µë³€ì„ êµ¬ì¡°í™”í•  ë•Œ ## ì œëª©ì„ ì‚¬ìš©í•˜ì„¸ìš”.`
    : `ë‹¹ì‹ ì€ ë„ì›€ì´ ë˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.\n\nì„œì‹ ê·œì¹™:\n- ì¤‘ìš”í•˜ê±°ë‚˜ ê°•ì¡°í•˜ê³  ì‹¶ì€ ë‚´ìš©: **ê°•ì¡°í•  ë‚´ìš©**\n- ì„¹ì…˜ ì œëª©ì´ë‚˜ ì£¼ìš” ì£¼ì œ: ## ì œëª© ë‚´ìš©${codeBlockRule}${summaryRule}`;
  
  const personaPrompt = persona ? buildPersonaPrompt(persona) : '';

  const systemContent = [baseSystemPrompt, personaPrompt, languageInstruction]
    .filter(Boolean)
    .join('\n\n');
  
  const finalMessages = systemContent
    ? [
        {
          role: 'system',
          content: systemContent
        },
        ...transformedMessages
      ]
    : transformedMessages;

  // Codex ëª¨ë¸ì€ /v1/responses ì—”ë“œí¬ì¸íŠ¸ ì‚¬ìš©
  const isCodex = selectedModel.includes('codex');
  const endpoint = isCodex 
    ? 'https://api.openai.com/v1/responses'
    : 'https://api.openai.com/v1/chat/completions';

  // GPT-5 ì‹œë¦¬ì¦ˆëŠ” temperatureë¥¼ ì§€ì›í•˜ì§€ ì•Šìœ¼ë¯€ë¡œ ì œì™¸
  const requestBody: any = {
    model: selectedModel,
    messages: finalMessages,
    max_completion_tokens: 2048,
    stream: false // ë¹„ìŠ¤íŠ¸ë¦¬ë°ìœ¼ë¡œ ë³€ê²½ (ê°„ê²°í•œ ì‘ë‹µ)
  };
  
  // GPT-5 ì‹œë¦¬ì¦ˆê°€ ì•„ë‹Œ ê²½ìš°ì—ë§Œ temperature ì¶”ê°€
  if (!isGPT5Series) {
    requestBody.temperature = 0.7;
  }

  // Responses APIëŠ” ë‹¤ë¥¸ íŒŒë¼ë¯¸í„° êµ¬ì¡° ì‚¬ìš©
  let apiRequestBody: any;
  if (isCodex) {
    apiRequestBody = {
      model: requestBody.model,
      input: requestBody.messages,
      max_tokens: requestBody.max_completion_tokens,
    };
    if (requestBody.temperature !== undefined) {
      apiRequestBody.temperature = requestBody.temperature;
    }
  } else {
    apiRequestBody = requestBody;
  }

  if (process.env.NODE_ENV !== 'production') {
    console.log(`[OpenAI] Request:`, { endpoint, model: selectedModel, stream: requestBody.stream });
  }

  // 20ì´ˆ íƒ€ì„ì•„ì›ƒ ì„¤ì • (Netlify 26ì´ˆ ì œí•œë³´ë‹¤ ì—¬ìœ ìˆê²Œ)
  const controller = new AbortController();
  const timeoutId = setTimeout(() => controller.abort(), 20000);

  let response: Response;
  try {
    response = await fetch(endpoint, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${apiKey}`
      },
      body: JSON.stringify(apiRequestBody),
      signal: controller.signal
    });
  } catch (fetchError: any) {
    clearTimeout(timeoutId);
    if (fetchError.name === 'AbortError') {
      throw new Error('OpenAI API ìš”ì²­ì´ 20ì´ˆë¥¼ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤. ë” ì§§ì€ ì§ˆë¬¸ì„ ì‹œë„í•´ë³´ì„¸ìš”.');
    }
    throw new Error(`OpenAI API í˜¸ì¶œ ì‹¤íŒ¨: ${fetchError.message}`);
  } finally {
    clearTimeout(timeoutId);
  }

  if (!response.ok) {
    const errorData = await response.json().catch(() => ({}));
    if (process.env.NODE_ENV !== 'production') {
      console.error('[OpenAI] Error response:', errorData);
    }
    const error: any = new Error(errorData.error?.message || 'OpenAI API ì˜¤ë¥˜');
    error.status = response.status;
    error.response = { status: response.status, headers: response.headers };
    
    // 429 ì—ëŸ¬ ì²˜ë¦¬
    if (response.status === 429 && retryCount < 3) {
      const rateLimitInfo = parseRateLimitError(error);
      
      if (rateLimitInfo.isRateLimit) {
        apiKeyManager.handleRateLimitError('openai', apiKey, rateLimitInfo.resetTime, rateLimitInfo.rateLimitType);
        
        const nextKey = apiKeyManager.getAvailableKey('openai');
        if (nextKey && nextKey !== apiKey) {
          return executeOpenAIRequest(model, messages, nextKey, userAttachments, persona, retryCount + 1, languageInstruction);
        }
        
        const availability = apiKeyManager.getNextAvailableTime('openai');
        throw new Error(availability.message || 'OpenAI API ìš”ì²­ í•œë„ë¥¼ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤.');
      }
    }
    
    throw error;
  }

  // ë¹„ìŠ¤íŠ¸ë¦¬ë° JSON ì‘ë‹µ ì²˜ë¦¬
  const data = await response.json();
  
  if (process.env.NODE_ENV !== 'production') {
    console.log('[OpenAI] Full response data:', JSON.stringify(data, null, 2));
  }
  
  // choices ë°°ì—´ í™•ì¸
  if (!data?.choices || !Array.isArray(data.choices) || data.choices.length === 0) {
    console.error('[OpenAI] No choices in response. Full data:', JSON.stringify(data));
    throw new Error('OpenAI API ì‘ë‹µì— choicesê°€ ì—†ìŠµë‹ˆë‹¤. ê´€ë¦¬ìì—ê²Œ ë¬¸ì˜í•˜ì„¸ìš”.');
  }

  const choice = data.choices[0];
  
  // refusal ì²´í¬ (GPT-4o ì´ìƒì—ì„œ ê±°ë¶€ ì‘ë‹µ)
  if (choice.message?.refusal) {
    console.warn('[OpenAI] Request was refused:', choice.message.refusal);
    throw new Error(`OpenAIê°€ ìš”ì²­ì„ ê±°ë¶€í–ˆìŠµë‹ˆë‹¤: ${choice.message.refusal}`);
  }
  
  // Codex (Responses API) vs Chat Completions API
  const content = isCodex
    ? (data?.output?.[0]?.content?.[0]?.text || choice.message?.content)
    : choice.message?.content;

  if (process.env.NODE_ENV !== 'production') {
    console.log('[OpenAI] Extracted content:', content);
    console.log('[OpenAI] Content type:', typeof content);
    console.log('[OpenAI] Content length:', content?.length);
    console.log('[OpenAI] Choice structure:', JSON.stringify(choice, null, 2));
  }

  if (!content || (typeof content === 'string' && !content.trim())) {
    console.error('[OpenAI] Empty content detected.');
    console.error('[OpenAI] Choice:', JSON.stringify(choice));
    console.error('[OpenAI] Full data:', JSON.stringify(data));
    throw new Error('OpenAI APIì—ì„œ ë¹ˆ ì‘ë‹µì„ ë°˜í™˜í–ˆìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ì§ˆë¬¸ì„ ì‹œë„í•´ë³´ì„¸ìš”.');
  }

  return content;
}

// Google AI Studio (Gemini) í˜¸ì¶œ (ë¹„ìŠ¤íŠ¸ë¦¬ë° JSON - Netlify í˜¸í™˜)
async function callGemini(model: string, messages: any[], userAttachments?: UserAttachment[], retryCount: number = 0, temperature?: number): Promise<string> {
  const apiKey = apiKeyManager.getAvailableKey('gemini');
  if (!apiKey) {
    throw new Error('Gemini API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. GOOGLE_API_KEY ë˜ëŠ” GEMINI_API_KEYë¥¼ ì„¤ì •í•˜ì„¸ìš”.');
  }

  const geminiModelMap: { [key: string]: string } = {
    'gemini3': 'gemini-1.5-flash',
    'gemini3pro': 'gemini-1.5-pro',
    // ë ˆê±°ì‹œ ë§¤í•‘
    'gemini-flash': 'gemini-1.5-flash',
    'gemini-pro': 'gemini-1.5-pro',
  };

  const selectedModel = geminiModelMap[model] || 'gemini-1.5-flash';

  // Gemini contents ë³€í™˜
  const contents: Array<{ role: string; parts: any[] }> = [];
  const append = (role: 'user' | 'model', part: any) => {
    if (contents.length === 0 || contents[contents.length - 1].role !== role) {
      contents.push({ role, parts: [part] });
    } else {
      contents[contents.length - 1].parts.push(part);
    }
  };

  // ê¸°ì¡´ ëŒ€í™” ë³€í™˜ (assistant -> model)
  for (const m of messages) {
    const role = m.role === 'assistant' ? 'model' : 'user';
    if (Array.isArray(m.content)) {
      for (const p of m.content) {
        if (p?.type === 'text' && p?.text) {
          append(role, { text: p.text });
        } else if (p?.type === 'image_url' && p?.image_url?.url) {
          const parsed = extractBase64(p.image_url.url);
          if (parsed) {
            append(role, { inline_data: { mime_type: parsed.mime, data: parsed.base64 } });
          }
        }
      }
    } else if (typeof m.content === 'string') {
      append(role, { text: m.content });
    }
  }

  // ë§ˆì§€ë§‰ user ë©”ì‹œì§€ì— ì²¨ë¶€ ì¶”ê°€
  if (userAttachments?.length) {
    for (let i = contents.length - 1; i >= 0; i--) {
      if (contents[i].role === 'user') {
        for (const att of userAttachments) {
          if (att.type === 'image' && att.dataUrl) {
            const parsed = extractBase64(att.dataUrl);
            if (parsed) contents[i].parts.push({ inline_data: { mime_type: parsed.mime, data: parsed.base64 } });
          } else if (att.type === 'text' && att.content) {
            contents[i].parts.push({ text: `File (${att.name}):\n${att.content.slice(0, 4000)}` });
          }
        }
        break;
      }
    }
  }

  // generateContent ì—”ë“œí¬ì¸íŠ¸ ì‚¬ìš© (ë¹„ìŠ¤íŠ¸ë¦¬ë° - Netlify íƒ€ì„ì•„ì›ƒ ë°©ì§€)
  const response = await fetch(`https://generativelanguage.googleapis.com/v1beta/models/${encodeURIComponent(selectedModel)}:generateContent?key=${apiKey}`, {
    method: 'POST',
    headers: { 'Content-Type': 'application/json' },
    body: JSON.stringify({
      contents,
      generationConfig: { 
        temperature: temperature ?? 0.7,
        maxOutputTokens: 2048,
        topP: 0.95,
        topK: 40
      },
    }),
  });

  if (!response.ok) {
    let data: any = {};
    try { data = await response.json(); } catch { /* ignore */ }
    const msg = data?.error?.message || 'Gemini API ì˜¤ë¥˜';
    const error: any = new Error(msg);
    error.status = response.status;
    error.response = { status: response.status, headers: response.headers };
    
    // 429 ì—ëŸ¬ ì²˜ë¦¬
    if (response.status === 429 && retryCount < 3) {
      const rateLimitInfo = parseRateLimitError(error);
      
      if (rateLimitInfo.isRateLimit) {
        apiKeyManager.handleRateLimitError('gemini', apiKey, rateLimitInfo.resetTime, rateLimitInfo.rateLimitType);
        
        const nextKey = apiKeyManager.getAvailableKey('gemini');
        if (nextKey && nextKey !== apiKey) {
          return callGemini(model, messages, userAttachments, retryCount + 1, temperature);
        }
        
        const availability = apiKeyManager.getNextAvailableTime('gemini');
        throw new Error(availability.message || 'Gemini API ìš”ì²­ í•œë„ë¥¼ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤.');
      }
    }
    
    throw error;
  }

  // ë¹„ìŠ¤íŠ¸ë¦¬ë° JSON ì‘ë‹µ ì²˜ë¦¬
  const data = await response.json();
  const parts = data?.candidates?.[0]?.content?.parts || [];
  const content = parts.map((p: any) => p?.text).filter(Boolean).join('');

  if (!content || !content.trim()) {
    throw new Error('Gemini APIì—ì„œ ë¹ˆ ì‘ë‹µì„ ë°˜í™˜í–ˆìŠµë‹ˆë‹¤.');
  }

  return content;
}


// Anthropic API í˜¸ì¶œ (ë¹„ìŠ¤íŠ¸ë¦¬ë° JSON - Netlify í˜¸í™˜)
async function callAnthropic(model: string, messages: any[], userAttachments?: UserAttachment[], retryCount: number = 0, temperature?: number): Promise<string> {
  const apiKey = apiKeyManager.getAvailableKey('anthropic');
  
  if (!apiKey) {
    throw new Error('Anthropic API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.');
  }

  const modelMap: { [key: string]: string } = {
    'haiku35': 'claude-3-5-haiku-20241022',
    'haiku45': 'claude-3-5-haiku-20241022',
    'sonnet45': 'claude-3-5-sonnet-20241022',
    'opus4': 'claude-opus-4-20250514',
    'opus41': 'claude-opus-4.1-20241022',
    'opus45': 'claude-opus-4.1-20241022', // ì„ì‹œ ë§¤í•‘
    'opus46': 'claude-opus-4.6-20250514',
    // ë ˆê±°ì‹œ ë§¤í•‘
    'claude-haiku': 'claude-3-haiku-20240307',
    'claude-sonnet': 'claude-3-5-sonnet-20241022',
    'claude-opus': 'claude-3-opus-20240229',
  };

  // Anthropic í˜•ì‹ìœ¼ë¡œ ë³€í™˜ (system ë©”ì‹œì§€ ë¶„ë¦¬)
  const systemMessage = messages.find((m: any) => m.role === 'system');
  const conversationMessages = messages.filter((m: any) => m.role !== 'system');

  // Transform to Anthropic content blocks; add image/text attachments to the LAST user message
  const transformed = conversationMessages.map((m: any) => ({
    role: m.role,
    content: Array.isArray(m.content)
      ? m.content
      : [{ type: 'text', text: typeof m.content === 'string' ? m.content : '' }]
  }));

  if (userAttachments?.length) {
    for (let i = transformed.length - 1; i >= 0; i--) {
      if (transformed[i].role === 'user') {
        userAttachments.forEach(att => {
          if (att.type === 'image' && att.dataUrl) {
            const parsed = extractBase64(att.dataUrl);
            if (parsed) {
              transformed[i].content.push({
                type: 'image',
                source: { type: 'base64', media_type: parsed.mime, data: parsed.base64 }
              } as any);
            }
          } else if (att.type === 'text' && att.content) {
            transformed[i].content.push({ type: 'text', text: `File (${att.name}):\n${att.content.slice(0, 4000)}` });
          }
        });
        break;
      }
    }
  }

  const response = await fetch('https://api.anthropic.com/v1/messages', {
    method: 'POST',
    headers: {
      'Content-Type': 'application/json',
      'x-api-key': apiKey,
      'anthropic-version': '2023-06-01'
    },
    body: JSON.stringify({
      model: modelMap[model] || 'claude-3-5-sonnet-20241022',
      max_tokens: 2048,
      temperature: temperature ?? 1.0,
      top_p: 0.9,
      stream: false, // ë¹„ìŠ¤íŠ¸ë¦¬ë°ìœ¼ë¡œ ë³€ê²½ (ê°„ê²°í•œ ì‘ë‹µ)
      system: systemMessage?.content || 'ë‹¹ì‹ ì€ ë„ì›€ì´ ë˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.',
      messages: transformed
    })
  });

  if (!response.ok) {
    const errorData = await response.json().catch(() => ({}));
    const error: any = new Error(errorData.error?.message || 'Anthropic API ì˜¤ë¥˜');
    error.status = response.status;
    error.response = { status: response.status, headers: response.headers };
    
    // 429 ì—ëŸ¬ ì²˜ë¦¬
    if (response.status === 429 && retryCount < 3) {
      const rateLimitInfo = parseRateLimitError(error);
      
      if (rateLimitInfo.isRateLimit) {
        apiKeyManager.handleRateLimitError('anthropic', apiKey, rateLimitInfo.resetTime, rateLimitInfo.rateLimitType);
        
        const nextKey = apiKeyManager.getAvailableKey('anthropic');
        if (nextKey && nextKey !== apiKey) {
          return callAnthropic(model, messages, userAttachments, retryCount + 1, temperature);
        }
        
        const availability = apiKeyManager.getNextAvailableTime('anthropic');
        throw new Error(availability.message || 'Anthropic API ìš”ì²­ í•œë„ë¥¼ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤.');
      }
    }
    
    throw error;
  }

  // ë¹„ìŠ¤íŠ¸ë¦¬ë° JSON ì‘ë‹µ ì²˜ë¦¬
  const data = await response.json();
  const content = data?.content?.map((c: any) => c.type === 'text' ? c.text : '').filter(Boolean).join('') || '';

  if (!content || !content.trim()) {
    throw new Error('Anthropic APIì—ì„œ ë¹ˆ ì‘ë‹µì„ ë°˜í™˜í–ˆìŠµë‹ˆë‹¤.');
  }

  return content;
}

// Perplexity API í˜¸ì¶œ (ë¹„ìŠ¤íŠ¸ë¦¬ë° JSON - Netlify ì™„ë²½ í˜¸í™˜)
async function callPerplexity(model: string, messages: any[], userAttachments?: UserAttachment[], retryCount: number = 0, temperature?: number): Promise<string> {
  const apiKey = apiKeyManager.getAvailableKey('perplexity');
  
  if (!apiKey) {
    throw new Error('Perplexity API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.');
  }

  const modelMap: { [key: string]: string } = {
    'sonar': 'sonar',
    'sonarPro': 'sonar-pro',
    'deepResearch': 'sonar-reasoning',
    'perplexity-sonar': 'sonar',
    'perplexity-sonar-pro': 'sonar-pro',
    'perplexity-deep-research': 'sonar-reasoning'
  };

  // ì²¨ë¶€íŒŒì¼ ë©”ëª¨ ì¶”ê°€
  let finalMessages = messages;
  if (userAttachments?.length) {
    finalMessages = [...messages];
    const lastUserIdx = finalMessages.map((m: any) => m.role).lastIndexOf('user');
    if (lastUserIdx !== -1) {
      const last = finalMessages[lastUserIdx];
      finalMessages[lastUserIdx] = {
        ...last,
        content: `${last.content || ''}\n\n[ì²¨ë¶€ ${userAttachments.length}ê°œëŠ” ì´ ëª¨ë¸ì—ì„œ ì§ì ‘ ì²˜ë¦¬ë˜ì§€ ì•Šì•„ ì œì™¸ë˜ì—ˆìŠµë‹ˆë‹¤.]`
      };
    }
  }

  const response = await fetch('https://api.perplexity.ai/chat/completions', {
    method: 'POST',
    headers: {
      'Content-Type': 'application/json',
      'Authorization': `Bearer ${apiKey}`
    },
    body: JSON.stringify({
      model: modelMap[model] || 'sonar',
      stream: false, // ë¹„ìŠ¤íŠ¸ë¦¬ë°ìœ¼ë¡œ ë³€ê²½ (ê°„ê²°í•œ ì‘ë‹µ)
      messages: finalMessages,
      max_tokens: 2048,
      temperature: temperature ?? 0.7,
      top_p: 0.9,
    })
  });

  if (!response.ok) {
    let errorData: any = {};
    try { errorData = await response.json(); } catch {}
    const error: any = new Error(errorData.error?.message || `Perplexity API ì˜¤ë¥˜ (${response.status})`);
    error.status = response.status;
    error.response = { status: response.status, headers: response.headers };

    if (response.status === 429 && retryCount < 3) {
      const rateLimitInfo = parseRateLimitError(error);
      if (rateLimitInfo.isRateLimit) {
        apiKeyManager.handleRateLimitError('perplexity', apiKey, rateLimitInfo.resetTime, rateLimitInfo.rateLimitType);
        const nextKey = apiKeyManager.getAvailableKey('perplexity');
        if (nextKey && nextKey !== apiKey) {
          return callPerplexity(model, messages, userAttachments, retryCount + 1, temperature);
        }
        const availability = apiKeyManager.getNextAvailableTime('perplexity');
        throw new Error(availability.message || 'Perplexity API ìš”ì²­ í•œë„ë¥¼ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤.');
      }
    }

    throw error;
  }

  // ë¹„ìŠ¤íŠ¸ë¦¬ë° JSON ì‘ë‹µ ì²˜ë¦¬
  const data = await response.json();
  const content = data?.choices?.[0]?.message?.content;

  if (!content || !content.trim()) {
    throw new Error('Perplexity APIì—ì„œ ë¹ˆ ì‘ë‹µì„ ë°˜í™˜í–ˆìŠµë‹ˆë‹¤.');
  }

  return content;
}

export async function POST(request: NextRequest) {
  if (isStaticExportPhase) {
    return NextResponse.json(
      { error: 'ì •ì  ë‚´ë³´ë‚´ê¸° í™˜ê²½ì—ì„œëŠ” Chat APIë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.' },
      {
        status: 501,
        headers: {
          'Cache-Control': 'no-store',
          Pragma: 'no-cache',
          Expires: '0',
        },
      }
    );
  }

  try {
    // Rate Limiting ì²´í¬
    const clientIp = getClientIp(request);
    const rateLimitResult = chatRateLimiter.check(clientIp);

    if (!rateLimitResult.success) {
      return NextResponse.json(
        { 
          error: 'ìš”ì²­ í•œë„ë¥¼ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.',
          retryAfter: Math.ceil((rateLimitResult.reset - Date.now()) / 1000)
        },
        { 
          status: 429,
          headers: {
            'X-RateLimit-Limit': rateLimitResult.limit.toString(),
            'X-RateLimit-Remaining': rateLimitResult.remaining.toString(),
            'X-RateLimit-Reset': new Date(rateLimitResult.reset).toISOString(),
            'Retry-After': Math.ceil((rateLimitResult.reset - Date.now()) / 1000).toString()
          }
        }
      );
    }

    const { modelId, messages, userAttachments, persona, language, temperature, storedFacts, conversationSummary } = await request.json();

    const resolvedLanguage = (language === 'en' || language === 'ja' || language === 'ko') ? language : 'ko';
    const languageInstruction = resolvedLanguage === 'en'
      ? 'Always respond in English.'
      : resolvedLanguage === 'ja'
      ? 'å¿…ãšæ—¥æœ¬èªã§å›ç­”ã—ã¦ãã ã•ã„ã€‚'
      : 'ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”.';

    const normalizeStoredFact = (fact: unknown) => {
      if (typeof fact !== 'string') return '';
      const cleaned = fact.trim().replace(/\s+/g, ' ');
      return cleaned.slice(0, 200);
    };

    const storedFactsList: string[] = Array.isArray(storedFacts)
      ? Array.from(new Set(storedFacts.map(normalizeStoredFact).filter(Boolean))).slice(0, 50)
      : [];

    const storedFactsContext = storedFactsList.length
      ? ['[ì €ì¥ëœ ì‚¬ìš©ì ì‚¬ì‹¤(ì°¸ê³ ìš©, ì¶œë ¥ ê¸ˆì§€)]', ...storedFactsList].join('\n')
      : '';

    const memoryInstruction = [
      'ì•„ë˜ ê·œì¹™ì„ ë°˜ë“œì‹œ ì¤€ìˆ˜í•˜ì„¸ìš”.',
      '1) ë‹µë³€ ë³¸ë¬¸ì„ ë¨¼ì € ì¶œë ¥í•œ ë’¤, ë°˜ë“œì‹œ ë‹µë³€ì˜ ë§¨ ë§ˆì§€ë§‰ì—ë§Œ ìˆ¨ê¹€ ë©”ëª¨ë¦¬ ë¸”ë¡ì„ ì¶”ê°€í•˜ì„¸ìš”.',
      '2) ìˆ¨ê¹€ ë©”ëª¨ë¦¬ ë¸”ë¡ í˜•ì‹ì€ ì •í™•íˆ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤(ë”°ì˜´í‘œ/ì½”ë“œë¸”ë¡/ë§ˆí¬ë‹¤ìš´ ê¸ˆì§€):',
      '@@MEM@@',
      '<ìƒˆë¡­ê²Œ í•™ìŠµí•œ, ì¼ë°˜í™” ê°€ëŠ¥í•œ ì‚¬ìš©ì ì‚¬ì‹¤ì„ í•œ ì¤„ì— í•˜ë‚˜ì”©>',
      '@@END@@',
      '3) ìƒˆ ì‚¬ì‹¤ì´ ì—†ìœ¼ë©´ ë¹ˆ ë¸”ë¡ì„ ì¶œë ¥í•˜ì„¸ìš”:',
      '@@MEM@@',
      '@@END@@',
      '4) ë©”ëª¨ë¦¬ì—ëŠ” ì¸ì‚¬/ë†ë‹´/ê°ì •í‘œí˜„/ë§íˆ¬/ì´ëª¨ì§€ ì„ í˜¸/ìš”ì²­ ë°˜ë³µ/ì¶”ì¸¡/ë¯¼ê°ì •ë³´/ê°œì¸ì‹ë³„ ê°€ëŠ¥í•œ ì„¸ë¶€ì •ë³´ë¥¼ ì“°ì§€ ë§ˆì„¸ìš”.',
      '5) ë©”ëª¨ë¦¬ëŠ” ë§¤ìš° ê°„ê²°í•˜ê²Œ, ê° ì¤„ 120ì ì´ë‚´ë¡œ ì‘ì„±í•˜ê³ , ë©”ëª¨ë¦¬ ì¤„ì˜ ì–¸ì–´ëŠ” í˜„ì¬ ë‹µë³€ ì–¸ì–´ì™€ ë™ì¼í•˜ê²Œ í•˜ì„¸ìš”.',
    ].join('\n');

    const languageInstructionWithMemory = [languageInstruction, storedFactsContext, memoryInstruction]
      .filter(Boolean)
      .join('\n\n');

    // ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ ì¶”ê°€
    const basePrompt = 'Energetic. Friendly.\nReact big. Use emojis.\nGive practical lists.';

    const applyLanguageInstruction = (inputMessages: any[]) => {
      const idx = inputMessages.findIndex((m: any) => m?.role === 'system');
      
      // ìš”ì•½ì´ ìˆìœ¼ë©´ ì „ì²´ ë©”ì‹œì§€ ëŒ€ì‹  ìš”ì•½ë§Œ ì‚¬ìš©
      let contextMessages = inputMessages;
      if (conversationSummary && inputMessages.length > 1) {
        // ë§ˆì§€ë§‰ ì‚¬ìš©ì ë©”ì‹œì§€ë§Œ ìœ ì§€í•˜ê³  ë‚˜ë¨¸ì§€ëŠ” ìš”ì•½ìœ¼ë¡œ ëŒ€ì²´
        const lastUserMessage = inputMessages[inputMessages.length - 1];
        contextMessages = [
          {
            role: 'system',
            content: `Previous conversation summary:\n${conversationSummary}`
          },
          lastUserMessage
        ];
      }
      
      const systemContent = [basePrompt, languageInstructionWithMemory].filter(Boolean).join('\n\n');
      
      if (idx === -1) {
        return [{ role: 'system', content: systemContent }, ...contextMessages];
      }
      
      const existing = contextMessages[idx];
      const existingContent = typeof existing?.content === 'string' ? existing.content : '';
      const merged = [existingContent, systemContent].filter(Boolean).join('\n\n');
      
      return [
        ...contextMessages.slice(0, idx),
        { ...existing, content: merged },
        ...contextMessages.slice(idx + 1),
      ];
    };

    // ì…ë ¥ ê²€ì¦
    if (!modelId || !messages || !Array.isArray(messages)) {
      return NextResponse.json(
        { error: 'ì˜ëª»ëœ ìš”ì²­ì…ë‹ˆë‹¤.' },
        { status: 400 }
      );
    }

    // ë©”ì‹œì§€ ê¸¸ì´ ì œí•œ (DoS ë°©ì§€)
    if (messages.length > 100) {
      return NextResponse.json(
        { error: 'ë©”ì‹œì§€ ê°œìˆ˜ê°€ ë„ˆë¬´ ë§ìŠµë‹ˆë‹¤.' },
        { status: 400 }
      );
    }

    // ê° ë©”ì‹œì§€ ë‚´ìš© ê¸¸ì´ ì œí•œ
    for (const msg of messages) {
      if (typeof msg.content === 'string' && msg.content.length > 50000) {
        return NextResponse.json(
          { error: 'ë©”ì‹œì§€ ë‚´ìš©ì´ ë„ˆë¬´ ê¹ë‹ˆë‹¤.' },
          { status: 400 }
        );
      }
    }

    // ì²¨ë¶€íŒŒì¼ í¬ê¸° ì œí•œ
    if (userAttachments && Array.isArray(userAttachments)) {
      if (userAttachments.length > 10) {
        return NextResponse.json(
          { error: 'ì²¨ë¶€íŒŒì¼ ê°œìˆ˜ê°€ ë„ˆë¬´ ë§ìŠµë‹ˆë‹¤.' },
          { status: 400 }
        );
      }
      
      for (const attachment of userAttachments) {
        if (attachment.dataUrl && attachment.dataUrl.length > 10 * 1024 * 1024) {
          return NextResponse.json(
            { error: 'ì²¨ë¶€íŒŒì¼ í¬ê¸°ê°€ ë„ˆë¬´ í½ë‹ˆë‹¤. (ìµœëŒ€ 10MB)' },
            { status: 400 }
          );
        }
      }
    }

    // ê°œë°œ í™˜ê²½ì—ì„œë§Œ ë¡œê¹…
    if (process.env.NODE_ENV === 'development') {
      console.log(`[Chat API] Model: ${modelId}, Messages: ${messages.length}`);
    }

    // ëª¨ë¸ ì‹œë¦¬ì¦ˆë³„ë¡œ API í˜¸ì¶œ - ëª¨ë“  ëª¨ë¸ JSON ì‘ë‹µ ë°˜í™˜
    let responseContent: string;

    if (modelId.startsWith('gpt') || modelId === 'codex' || modelId.endsWith('codex') || modelId === 'gptimage1' || modelId === 'dalle3') {
      if (process.env.NODE_ENV !== 'production') {
        console.log(`[Chat API] Calling OpenAI API${modelId === 'gptimage1' || modelId === 'dalle3' ? ' (Image Generation)' : ''}`);
      }
      responseContent = await callOpenAI(modelId, messages, userAttachments, persona, languageInstructionWithMemory);
    } else if (modelId.startsWith('gemini')) {
      if (process.env.NODE_ENV !== 'production') {
        console.log('[Chat API] Calling Gemini API');
      }
      responseContent = await callGemini(modelId, applyLanguageInstruction(messages), userAttachments, 0, temperature);
    } else if (modelId.startsWith('claude') || modelId === 'haiku35' || modelId === 'haiku45' || modelId === 'sonnet45' || modelId === 'opus4' || modelId === 'opus41' || modelId === 'opus45' || modelId === 'opus46') {
      if (process.env.NODE_ENV !== 'production') {
        console.log('[Chat API] Calling Anthropic API');
      }
      responseContent = await callAnthropic(modelId, applyLanguageInstruction(messages), userAttachments, 0, temperature);
    } else if (modelId.startsWith('perplexity') || modelId === 'sonar' || modelId === 'sonarPro' || modelId === 'deepResearch') {
      if (process.env.NODE_ENV !== 'production') {
        console.log('[Chat API] Calling Perplexity API');
      }
      responseContent = await callPerplexity(modelId, applyLanguageInstruction(messages), userAttachments, 0, temperature);
    } else {
      if (process.env.NODE_ENV !== 'production') {
        console.log('[Chat API] Unknown model, using demo response');
      }
      responseContent = `[${modelId}] ${resolvedLanguage === 'ja' ? 'ã“ã‚“ã«ã¡ã¯ï¼è³ªå•ã«ãŠç­”ãˆã—ã¾ã™ã€‚' : resolvedLanguage === 'en' ? 'Hello! I will answer your question.' : 'ì•ˆë…•í•˜ì„¸ìš”! ì§ˆë¬¸ì— ë‹µë³€ë“œë¦¬ê² ìŠµë‹ˆë‹¤.'} (API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•„ ë°ëª¨ ëª¨ë“œë¡œ ì‹¤í–‰ ì¤‘ì…ë‹ˆë‹¤. .env.local íŒŒì¼ì— API í‚¤ë¥¼ ì¶”ê°€í•˜ì„¸ìš”.)`;
    }

    return NextResponse.json({ content: responseContent });

  } catch (error: any) {
    if (process.env.NODE_ENV !== 'production') {
      console.error('Chat API Error:', error);
      console.error('Error stack:', error.stack);
    }
    
    // API í‚¤ê°€ ì—†ëŠ” ê²½ìš° ë°ëª¨ ì‘ë‹µ
    if (error.message.includes('API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤')) {
      return NextResponse.json({ 
        content: `ğŸ’¡ ë°ëª¨ ëª¨ë“œ: ì‹¤ì œ AI ì‘ë‹µì„ ë°›ìœ¼ë ¤ë©´ .env.local íŒŒì¼ì— API í‚¤ë¥¼ ì¶”ê°€í•˜ì„¸ìš”.\n\n` +
                 `ì„¤ì • ë°©ë²•:\n` +
                 `1. í”„ë¡œì íŠ¸ ë£¨íŠ¸ì— .env.local íŒŒì¼ ìƒì„±\n` +
                 `2. ë‹¤ìŒ í™˜ê²½ë³€ìˆ˜ ì¶”ê°€:\n` +
                 `   - OPENAI_API_KEY=your_key (GPT ëª¨ë¸ìš©)\n` +
                 `   - ANTHROPIC_API_KEY=your_key (Claude ëª¨ë¸ìš©)\n` +
                 `   - PERPLEXITY_API_KEY=your_key (Perplexity ëª¨ë¸ìš©)\n\n` +
                 `ìì„¸í•œ ë‚´ìš©ì€ env.example íŒŒì¼ì„ ì°¸ê³ í•˜ì„¸ìš”.`
      });
    }

    // ì—ëŸ¬ íƒ€ì…ë³„ ì²˜ë¦¬
    let errorMessage = 'ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.';
    let statusCode = 500;

    if (error.message?.includes('API í‚¤')) {
      errorMessage = error.message;
      statusCode = 401;
    } else if (error.message?.includes('í•œë„')) {
      errorMessage = error.message;
      statusCode = 429;
    } else if (error.message?.includes('ë„¤íŠ¸ì›Œí¬')) {
      errorMessage = 'ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì—°ê²°ì„ í™•ì¸í•˜ì„¸ìš”.';
      statusCode = 503;
    } else if (error.message) {
      errorMessage = error.message;
    }

    if (process.env.NODE_ENV !== 'production') {
      console.error(`[Chat API] Error:`, {
        message: errorMessage,
        stack: error.stack,
        timestamp: new Date().toISOString()
      });
    }
    
    return NextResponse.json(
      { error: errorMessage },
      { status: statusCode }
    );
  }
}

