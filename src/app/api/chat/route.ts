import { NextRequest, NextResponse } from 'next/server';
import { RateLimiter, getClientIp } from '@/lib/rateLimit';
import { apiKeyManager, parseRateLimitError } from '@/lib/apiKeyRotation';

// Rate Limiter ì¸ìŠ¤í„´ìŠ¤ ìƒì„± (ë¶„ë‹¹ 20íšŒ ì œí•œ)
const chatRateLimiter = new RateLimiter(20, 60 * 1000);

type UserAttachment = {
  type: 'image' | 'text';
  name: string;
  mimeType?: string;
  dataUrl?: string; // for images
  content?: string; // for text files
};

function extractBase64(dataUrl: string): { mime: string; base64: string } | null {
  try {
    const match = dataUrl.match(/^data:(.*?);base64,(.*)$/);
    if (!match) return null;
    return { mime: match[1], base64: match[2] };
  } catch {
    return null;
  }
}

// DALL-E ì´ë¯¸ì§€ ìƒì„± API í˜¸ì¶œ
async function callDALLE(prompt: string): Promise<string> {
  return apiKeyManager.enqueueRequest('openai', async () => {
    const apiKey = apiKeyManager.getAvailableKey('openai');
    
    if (!apiKey) {
      throw new Error('OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.');
    }

    if (process.env.NODE_ENV !== 'production') {
      console.log('[DALL-E] Generating image with prompt:', prompt);
    }

    const response = await fetch('https://api.openai.com/v1/images/generations', {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${apiKey}`
      },
      body: JSON.stringify({
        model: 'dall-e-3',
        prompt: prompt,
        n: 1,
        size: '1024x1024',
        quality: 'standard'
      })
    });

    if (!response.ok) {
      const errorData = await response.json();
      if (process.env.NODE_ENV !== 'production') {
        console.error('[DALL-E] Error response:', errorData);
      }
      throw new Error(errorData.error?.message || 'DALL-E API ì˜¤ë¥˜');
    }

    const data = await response.json();
    if (process.env.NODE_ENV !== 'production') {
      console.log('[DALL-E] Image generated successfully');
    }

    // ì´ë¯¸ì§€ URL ë°˜í™˜
    return data.data[0].url;
  });
}

// OpenAI API í˜¸ì¶œ (í‚¤ ë¡œí…Œì´ì…˜ ë° í ì‹œìŠ¤í…œ ì§€ì›) - ìŠ¤íŠ¸ë¦¬ë° Response ë°˜í™˜
async function callOpenAIStreaming(model: string, messages: any[], userAttachments?: UserAttachment[], persona?: any): Promise<Response> {
  // GPT-Image-1 ëª¨ë¸ì¸ ê²½ìš° DALL-E API ì‚¬ìš© (ìŠ¤íŠ¸ë¦¬ë° ë¶ˆí•„ìš”)
  if (model === 'gptimage1') {
    const lastUserMessage = [...messages].reverse().find((m: any) => m.role === 'user');
    const prompt = typeof lastUserMessage?.content === 'string' 
      ? lastUserMessage.content 
      : lastUserMessage?.content?.[0]?.text || 'ì•„ë¦„ë‹¤ìš´ í’ê²½';
    
    const imageUrl = await callDALLE(prompt);
    
    // ìŠ¤íŠ¸ë¦¬ë° í˜•ì‹ìœ¼ë¡œ ë°˜í™˜
    const encoder = new TextEncoder();
    const stream = new ReadableStream({
      start(controller) {
        controller.enqueue(encoder.encode(`data: ${JSON.stringify({ content: imageUrl })}\n\n`));
        controller.enqueue(encoder.encode('data: [DONE]\n\n'));
        controller.close();
      }
    });
    
    return new Response(stream, {
      headers: {
        'Content-Type': 'text/event-stream',
        'Cache-Control': 'no-cache',
        'Connection': 'keep-alive'
      }
    });
  }

  const apiKey = apiKeyManager.getAvailableKey('openai');
  if (!apiKey) {
    throw new Error('OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.');
  }

  return await executeOpenAIStreamingRequest(model, messages, apiKey, userAttachments, persona);
}

// OpenAI ì‹¤ì œ ìš”ì²­ ì‹¤í–‰ - ìŠ¤íŠ¸ë¦¬ë° Response ë°˜í™˜
async function executeOpenAIStreamingRequest(model: string, messages: any[], apiKey: string, userAttachments?: UserAttachment[], persona?: any, retryCount: number = 0): Promise<Response> {

  const modelMap: { [key: string]: string } = {
    // GPT ì‹œë¦¬ì¦ˆ
    'gpt5': process.env.GPT5_MODEL || 'gpt-5',
    'gpt51': process.env.GPT51_MODEL || 'gpt-5.1',
    'gpt4o': process.env.GPT4O_MODEL || 'gpt-4o',
    'gpt41': process.env.GPT41_MODEL || 'gpt-4.1',
    // OpenAI o ì‹œë¦¬ì¦ˆ
    'o3': process.env.O3_MODEL || 'o3',
    'o3mini': process.env.O3_MINI_MODEL || 'o3-mini',
    'o4mini': process.env.O4_MINI_MODEL || 'o4-mini',
    // ì½”ë”© ëª¨ë¸
    'codex': process.env.CODEX_MODEL || 'gpt-5-codex',
    'gpt5codex': process.env.GPT5_CODEX_MODEL || 'gpt-5-codex',
    'gpt51codex': process.env.GPT51_CODEX_MODEL || 'gpt-5.1-codex',
    // ì´ë¯¸ì§€ ëª¨ë¸
    'gptimage1': process.env.GPT_IMAGE_1_MODEL || 'dall-e-3',
  };

  // If there are image attachments, convert the LAST user message content to a multimodal array
  const transformedMessages = (() => {
    if (!userAttachments?.length) return messages;
    const lastIdx = [...messages].reverse().findIndex((m: any) => m.role === 'user');
    if (lastIdx === -1) return messages;
    const idx = messages.length - 1 - lastIdx;
    const last = messages[idx];
    const parts: any[] = [];
    if (typeof last.content === 'string') {
      parts.push({ type: 'text', text: last.content });
    } else if (Array.isArray(last.content)) {
      parts.push(...last.content);
    }
    userAttachments.forEach(att => {
      if (att.type === 'image' && att.dataUrl) {
        parts.push({ type: 'image_url', image_url: { url: att.dataUrl } });
      } else if (att.type === 'text' && att.content) {
        parts.push({ type: 'text', text: `File (${att.name}):\n${att.content.slice(0, 4000)}` });
      }
    });
    const newMsgs = [...messages];
    newMsgs[idx] = { role: 'user', content: parts };
    return newMsgs;
  })();

  const selectedModel = modelMap[model];
  if (!selectedModel) {
    throw new Error('ëª¨ë¸ ë§¤í•‘ì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. .env.localì˜ ëª¨ë¸ ë³€ìˆ˜ë¥¼ í™•ì¸í•˜ì„¸ìš”.');
  }

  // í˜ë¥´ì†Œë‚˜ ê¸°ë°˜ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ìƒì„±
  const buildPersonaPrompt = (persona: any) => {
    if (!persona) return '';
    
    let prompt = `ë‹¹ì‹ ì€ "${persona.name}"ì…ë‹ˆë‹¤.\n\n`;
    
    if (persona.personality) {
      const p = persona.personality;
      prompt += `ì„±ê²© íŠ¹ì„±:\n`;
      prompt += `- ë§íˆ¬: ${p.tone === 'formal' ? 'ê²©ì‹ìˆëŠ”' : p.tone === 'casual' ? 'ìºì£¼ì–¼í•œ' : p.tone === 'friendly' ? 'ì¹œê·¼í•œ' : p.tone === 'professional' ? 'ì „ë¬¸ì ì¸' : 'ìœ ë¨¸ëŸ¬ìŠ¤í•œ'}\n`;
      prompt += `- ì–¸ì–´ ìŠ¤íƒ€ì¼: ${p.language === 'polite' ? 'ì •ì¤‘í•œ' : p.language === 'casual' ? 'í¸í•œ' : 'ê¸°ìˆ ì ì¸'}\n`;
      prompt += `- ê°ì • í‘œí˜„ ìˆ˜ì¤€: ${p.emotionLevel}/10\n`;
      prompt += `- ì´ëª¨ì§€ ì‚¬ìš©: ${p.emojiUsage ? 'ì ê·¹ ì‚¬ìš©' : 'ì‚¬ìš© ì•ˆ í•¨'}\n`;
      prompt += `- ë‹µë³€ ê¸¸ì´: ${p.responseLength === 'concise' ? 'ê°„ê²°í•˜ê²Œ' : p.responseLength === 'balanced' ? 'ì ë‹¹í•˜ê²Œ' : 'ìƒì„¸í•˜ê²Œ'}\n\n`;
    }
    
    if (persona.expertise && persona.expertise.domains && persona.expertise.domains.length > 0) {
      prompt += `ì „ë¬¸ ë¶„ì•¼: ${persona.expertise.domains.join(', ')}\n`;
      prompt += `ì „ë¬¸ì„± ìˆ˜ì¤€: ${persona.expertise.level === 'beginner' ? 'ì´ˆê¸‰' : persona.expertise.level === 'intermediate' ? 'ì¤‘ê¸‰' : 'ì „ë¬¸ê°€'}\n\n`;
    }
    
    if (persona.speechPatterns) {
      if (persona.speechPatterns.greetings && persona.speechPatterns.greetings.length > 0) {
        prompt += `ì¸ì‚¬ë§ ì˜ˆì‹œ: ${persona.speechPatterns.greetings[0]}\n`;
      }
      if (persona.speechPatterns.catchPhrases && persona.speechPatterns.catchPhrases.length > 0) {
        prompt += `íŠ¹ì§•ì ì¸ í‘œí˜„: ${persona.speechPatterns.catchPhrases.join(', ')}\n`;
      }
    }
    
    prompt += `\nìœ„ íŠ¹ì„±ì„ ë°˜ì˜í•˜ì—¬ ë‹µë³€í•´ì£¼ì„¸ìš”.`;
    return prompt;
  };
  
  // GPT-5/5.1 ë° ì½”ë”© ëª¨ë¸ìš© ì‹œìŠ¤í…œ ë©”ì‹œì§€ ì¶”ê°€
  const isGPT5Series = model === 'gpt5' || model === 'gpt51';
  const isCodingModel = model === 'codex' || model === 'gpt5codex' || model === 'gpt51codex';
  
  const baseSystemPrompt = isGPT5Series
    ? 'ë‹¹ì‹ ì€ ë„ì›€ì´ ë˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ìµœëŒ€í•œ ìƒì„¸í•˜ê³  í¬ê´„ì ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”.\n\nì„œì‹ ê·œì¹™:\n- ì¤‘ìš”í•˜ê±°ë‚˜ ê°•ì¡°í•˜ê³  ì‹¶ì€ ë‚´ìš©: **ê°•ì¡°í•  ë‚´ìš©**\n- ì„¹ì…˜ ì œëª©ì´ë‚˜ ì£¼ìš” ì£¼ì œ: ## ì œëª© ë‚´ìš©\n\në‹µë³€ì„ êµ¬ì¡°í™”í•  ë•Œ ## ì œëª©ì„ ì ê·¹ í™œìš©í•˜ì„¸ìš”.'
    : isCodingModel
    ? 'ë‹¹ì‹ ì€ ì „ë¬¸ í”„ë¡œê·¸ë˜ë° ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. ì½”ë“œ ì‘ì„±, ë””ë²„ê¹…, ìµœì í™”, ì„¤ëª…ì— íŠ¹í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤.\n\nì„œì‹ ê·œì¹™:\n- ì½”ë“œëŠ” ëª…í™•í•˜ê³  íš¨ìœ¨ì ìœ¼ë¡œ ì‘ì„±í•˜ë©° ì£¼ì„ í¬í•¨\n- ì¤‘ìš”í•œ ë¶€ë¶„: **ê°•ì¡°**\n- ì„¹ì…˜ ì œëª©: ## ì œëª©\n\në‹µë³€ì„ êµ¬ì¡°í™”í•  ë•Œ ## ì œëª©ì„ ì‚¬ìš©í•˜ì„¸ìš”.'
    : '';
  
  const personaPrompt = persona ? buildPersonaPrompt(persona) : '';
  const systemContent = personaPrompt ? `${baseSystemPrompt}\n\n${personaPrompt}` : baseSystemPrompt;
  
  const finalMessages = (isGPT5Series || isCodingModel) && systemContent
    ? [
        {
          role: 'system',
          content: systemContent
        },
        ...transformedMessages
      ]
    : transformedMessages;

  // GPT-5 ì‹œë¦¬ì¦ˆëŠ” temperatureë¥¼ ì§€ì›í•˜ì§€ ì•Šìœ¼ë¯€ë¡œ ì œì™¸
  const requestBody: any = {
    model: selectedModel,
    messages: finalMessages,
    max_completion_tokens: isGPT5Series ? 2000 : 1500 // ì†ë„ ê°œì„ ì„ ìœ„í•´ í† í° ìˆ˜ ê°ì†Œ
  };
  
  // GPT-5 ì‹œë¦¬ì¦ˆê°€ ì•„ë‹Œ ê²½ìš°ì—ë§Œ temperature ì¶”ê°€
  if (!isGPT5Series) {
    requestBody.temperature = 0.7;
  }
  
  // ìŠ¤íŠ¸ë¦¬ë° í™œì„±í™”
  requestBody.stream = true;
  
  if (process.env.NODE_ENV !== 'production') {
    console.log(`[OpenAI] Request body:`, {
      model: requestBody.model,
      messageCount: requestBody.messages.length,
      maxTokens: requestBody.max_completion_tokens,
      stream: requestBody.stream
    });
  }

  // Codex ëª¨ë¸ì€ /v1/responses ì—”ë“œí¬ì¸íŠ¸ ì‚¬ìš©
  const isCodexModel = selectedModel.includes('codex');
  const endpoint = isCodexModel 
    ? 'https://api.openai.com/v1/responses'
    : 'https://api.openai.com/v1/chat/completions';
  
  if (process.env.NODE_ENV !== 'production') {
    console.log(`[OpenAI] Using endpoint: ${endpoint}`);
  }

  // Responses APIëŠ” ë‹¤ë¥¸ íŒŒë¼ë¯¸í„° êµ¬ì¡° ì‚¬ìš©
  let apiRequestBody: any;
  if (isCodexModel) {
    // Responses API í˜•ì‹
    apiRequestBody = {
      model: requestBody.model,
      input: requestBody.messages, // messages -> input
      max_tokens: requestBody.max_completion_tokens,
      stream: requestBody.stream
    };
    if (requestBody.temperature !== undefined) {
      apiRequestBody.temperature = requestBody.temperature;
    }
  } else {
    // Chat Completions API í˜•ì‹
    apiRequestBody = requestBody;
  }

  if (process.env.NODE_ENV !== 'production') {
    console.log(`[OpenAI] Request body structure:`, {
      endpoint,
      hasInput: 'input' in apiRequestBody,
      hasMessages: 'messages' in apiRequestBody
    });
  }

  const response = await fetch(endpoint, {
    method: 'POST',
    headers: {
      'Content-Type': 'application/json',
      'Authorization': `Bearer ${apiKey}`
    },
    body: JSON.stringify(apiRequestBody)
  });

  if (process.env.NODE_ENV !== 'production') {
    console.log(`[OpenAI] Response status: ${response.status}`);
  }
  
  if (!response.ok) {
    const errorData = await response.json();
    if (process.env.NODE_ENV !== 'production') {
      console.error('[OpenAI] Error response:', errorData);
    }
    const error: any = new Error(errorData.error?.message || 'OpenAI API ì˜¤ë¥˜');
    error.status = response.status;
    error.response = { status: response.status, headers: response.headers };
    
    // 429 ì—ëŸ¬ ì²˜ë¦¬
    if (response.status === 429 && retryCount < 3) {
      const rateLimitInfo = parseRateLimitError(error);
      
      if (rateLimitInfo.isRateLimit) {
        // í˜„ì¬ í‚¤ë¥¼ ì œí•œ ëª©ë¡ì— ì¶”ê°€
        apiKeyManager.handleRateLimitError('openai', apiKey, rateLimitInfo.resetTime, rateLimitInfo.rateLimitType);
        
        // ë‹¤ë¥¸ í‚¤ë¡œ ì¬ì‹œë„
        const nextKey = apiKeyManager.getAvailableKey('openai');
        if (nextKey && nextKey !== apiKey) {
          if (process.env.NODE_ENV !== 'production') {
            console.log(`OpenAI Rate Limit ê°ì§€. ë‹¤ë¥¸ í‚¤ë¡œ ì¬ì‹œë„ ì¤‘... (${retryCount + 1}/3)`);
          }
          return executeOpenAIStreamingRequest(model, messages, nextKey, userAttachments, persona, retryCount + 1);
        }
        
        // ëª¨ë“  í‚¤ê°€ ì œí•œëœ ê²½ìš°
        const availability = apiKeyManager.getNextAvailableTime('openai');
        throw new Error(availability.message || 'OpenAI API ìš”ì²­ í•œë„ë¥¼ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤.');
      }
    }
    
    throw error;
  }

  // ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µì„ Server-Sent Events í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•˜ì—¬ ë°˜í™˜
  const encoder = new TextEncoder();
  const decoder = new TextDecoder();
  
  const stream = new ReadableStream({
    async start(controller) {
      const reader = response.body?.getReader();
      if (!reader) {
        controller.close();
        return;
      }

      try {
        while (true) {
          const { done, value } = await reader.read();
          if (done) break;

          const chunk = decoder.decode(value, { stream: true });
          const lines = chunk.split('\n').filter(line => line.trim() !== '');

          for (const line of lines) {
            if (line.startsWith('data: ')) {
              const data = line.slice(6);
              
              if (data === '[DONE]') {
                controller.enqueue(encoder.encode('data: [DONE]\n\n'));
                continue;
              }

              try {
                const parsed = JSON.parse(data);
                const content = parsed.choices?.[0]?.delta?.content;
                
                if (content) {
                  // ì²­í¬ë¥¼ SSE í˜•ì‹ìœ¼ë¡œ ì „ë‹¬
                  controller.enqueue(encoder.encode(`data: ${JSON.stringify({ content })}\n\n`));
                }
              } catch (e) {
                // íŒŒì‹± ì—ëŸ¬ ë¬´ì‹œ
              }
            }
          }
        }
      } catch (error) {
        if (process.env.NODE_ENV !== 'production') {
          console.error('[OpenAI Streaming] Error:', error);
        }
      } finally {
        controller.close();
      }
    }
  });

  return new Response(stream, {
    headers: {
      'Content-Type': 'text/event-stream',
      'Cache-Control': 'no-cache',
      'Connection': 'keep-alive'
    }
  });
}

// Google AI Studio (Gemini) í˜¸ì¶œ (í‚¤ ë¡œí…Œì´ì…˜ ì§€ì›)
async function callGemini(model: string, messages: any[], userAttachments?: UserAttachment[], retryCount: number = 0): Promise<string> {
  const apiKey = apiKeyManager.getAvailableKey('gemini');
  if (!apiKey) {
    throw new Error('Gemini API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. GOOGLE_API_KEY ë˜ëŠ” GEMINI_API_KEYë¥¼ ì„¤ì •í•˜ì„¸ìš”.');
  }

  const geminiModelMap: { [key: string]: string } = {
    'gemini3': process.env.GEMINI_3_MODEL || 'gemini-3.0-flash',
    'gemini3pro': process.env.GEMINI_3_PRO_MODEL || 'gemini-3.0-pro',
    // ë ˆê±°ì‹œ ë§¤í•‘
    'gemini-flash': process.env.GEMINI_FLASH_MODEL || 'gemini-1.5-flash',
    'gemini-pro': process.env.GEMINI_PRO_MODEL || 'gemini-1.5-pro',
  };

  const selectedModel = geminiModelMap[model] || 'gemini-1.5-flash';

  // Gemini contents ë³€í™˜
  const contents: Array<{ role: string; parts: any[] }> = [];
  const append = (role: 'user' | 'model', part: any) => {
    if (contents.length === 0 || contents[contents.length - 1].role !== role) {
      contents.push({ role, parts: [part] });
    } else {
      contents[contents.length - 1].parts.push(part);
    }
  };

  // ê¸°ì¡´ ëŒ€í™” ë³€í™˜ (assistant -> model)
  for (const m of messages) {
    const role = m.role === 'assistant' ? 'model' : 'user';
    if (Array.isArray(m.content)) {
      // OpenAIì‹ ë©€í‹°ëª¨ë‹¬ partsë¥¼ í…ìŠ¤íŠ¸ë§Œ ìš°ì„  ë°˜ì˜
      for (const p of m.content) {
        if (p?.type === 'text' && p?.text) {
          append(role, { text: p.text });
        } else if (p?.type === 'image_url' && p?.image_url?.url) {
          const parsed = extractBase64(p.image_url.url);
          if (parsed) {
            append(role, { inline_data: { mime_type: parsed.mime, data: parsed.base64 } });
          }
        }
      }
    } else if (typeof m.content === 'string') {
      append(role, { text: m.content });
    }
  }

  // ë§ˆì§€ë§‰ user ë©”ì‹œì§€ì— ì²¨ë¶€ ì¶”ê°€
  if (userAttachments?.length) {
    for (let i = contents.length - 1; i >= 0; i--) {
      if (contents[i].role === 'user') {
        for (const att of userAttachments) {
          if (att.type === 'image' && att.dataUrl) {
            const parsed = extractBase64(att.dataUrl);
            if (parsed) contents[i].parts.push({ inline_data: { mime_type: parsed.mime, data: parsed.base64 } });
          } else if (att.type === 'text' && att.content) {
            contents[i].parts.push({ text: `File (${att.name}):\n${att.content.slice(0, 4000)}` });
          }
        }
        break;
      }
    }
  }

  const response = await fetch(`https://generativelanguage.googleapis.com/v1beta/models/${encodeURIComponent(selectedModel)}:generateContent?key=${apiKey}`, {
    method: 'POST',
    headers: { 'Content-Type': 'application/json' },
    body: JSON.stringify({
      contents,
      generationConfig: { temperature: 0.7, maxOutputTokens: 2048 },
    }),
  });

  const data = await response.json();
  if (!response.ok) {
    const msg = data?.error?.message || 'Gemini API ì˜¤ë¥˜';
    const error: any = new Error(msg);
    error.status = response.status;
    error.response = { status: response.status, headers: response.headers };
    
    // 429 ì—ëŸ¬ ì²˜ë¦¬
    if (response.status === 429 && retryCount < 3) {
      const rateLimitInfo = parseRateLimitError(error);
      
      if (rateLimitInfo.isRateLimit) {
        apiKeyManager.handleRateLimitError('gemini', apiKey, rateLimitInfo.resetTime, rateLimitInfo.rateLimitType);
        
        const nextKey = apiKeyManager.getAvailableKey('gemini');
        if (nextKey && nextKey !== apiKey) {
          if (process.env.NODE_ENV !== 'production') {
            console.log(`Gemini Rate Limit ê°ì§€. ë‹¤ë¥¸ í‚¤ë¡œ ì¬ì‹œë„ ì¤‘... (${retryCount + 1}/3)`);
          }
          return callGemini(model, messages, userAttachments, retryCount + 1);
        }
        
        const availability = apiKeyManager.getNextAvailableTime('gemini');
        throw new Error(availability.message || 'Gemini API ìš”ì²­ í•œë„ë¥¼ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤.');
      }
    }
    
    throw error;
  }

  // candidates[0].content.parts[*].text ê²°í•©
  const parts = data?.candidates?.[0]?.content?.parts || [];
  const text = parts.map((p: any) => p?.text).filter(Boolean).join('\n');
  return text || '[Gemini] ë¹ˆ ì‘ë‹µ';
}


// Anthropic API í˜¸ì¶œ (í‚¤ ë¡œí…Œì´ì…˜ ì§€ì›)
async function callAnthropic(model: string, messages: any[], userAttachments?: UserAttachment[], retryCount: number = 0): Promise<string> {
  const apiKey = apiKeyManager.getAvailableKey('anthropic');
  
  if (!apiKey) {
    throw new Error('Anthropic API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.');
  }

  const modelMap: { [key: string]: string } = {
    'haiku35': process.env.HAIKU_35_MODEL || 'claude-3-5-haiku-20241022',
    'sonnet45': process.env.SONNET_45_MODEL || 'claude-3-5-sonnet-20241022',
    'opus4': process.env.OPUS_4_MODEL || 'claude-opus-4-20250514',
    'opus41': process.env.OPUS_41_MODEL || 'claude-opus-4.1-20250514',
    'opus45': process.env.OPUS_45_MODEL || 'claude-opus-4.5-20250514',
    // ë ˆê±°ì‹œ ë§¤í•‘
    'claude-haiku': process.env.CLAUDE_HAIKU_MODEL || 'claude-3-haiku-20240307',
    'claude-sonnet': process.env.CLAUDE_SONNET_MODEL || 'claude-3-5-sonnet-20241022',
    'claude-opus': process.env.CLAUDE_OPUS_MODEL || 'claude-3-opus-20240229'
  };

  // Anthropic í˜•ì‹ìœ¼ë¡œ ë³€í™˜ (system ë©”ì‹œì§€ ë¶„ë¦¬)
  const systemMessage = messages.find((m: any) => m.role === 'system');
  const conversationMessages = messages.filter((m: any) => m.role !== 'system');

  // Transform to Anthropic content blocks; add image/text attachments to the LAST user message
  const transformed = conversationMessages.map((m: any) => ({
    role: m.role,
    content: Array.isArray(m.content)
      ? m.content
      : [{ type: 'text', text: typeof m.content === 'string' ? m.content : '' }]
  }));

  if (userAttachments?.length) {
    for (let i = transformed.length - 1; i >= 0; i--) {
      if (transformed[i].role === 'user') {
        userAttachments.forEach(att => {
          if (att.type === 'image' && att.dataUrl) {
            const parsed = extractBase64(att.dataUrl);
            if (parsed) {
              transformed[i].content.push({
                type: 'image',
                source: { type: 'base64', media_type: parsed.mime, data: parsed.base64 }
              } as any);
            }
          } else if (att.type === 'text' && att.content) {
            transformed[i].content.push({ type: 'text', text: `File (${att.name}):\n${att.content.slice(0, 4000)}` });
          }
        });
        break;
      }
    }
  }

  const response = await fetch('https://api.anthropic.com/v1/messages', {
    method: 'POST',
    headers: {
      'Content-Type': 'application/json',
      'x-api-key': apiKey,
      'anthropic-version': '2023-06-01'
    },
    body: JSON.stringify({
      model: modelMap[model] || 'claude-3-5-sonnet-20241022',
      max_tokens: 2000,
      system: systemMessage?.content || 'ë‹¹ì‹ ì€ ë„ì›€ì´ ë˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.',
      messages: transformed
    })
  });

  if (!response.ok) {
    const errorData = await response.json();
    const error: any = new Error(errorData.error?.message || 'Anthropic API ì˜¤ë¥˜');
    error.status = response.status;
    error.response = { status: response.status, headers: response.headers };
    
    // 429 ì—ëŸ¬ ì²˜ë¦¬
    if (response.status === 429 && retryCount < 3) {
      const rateLimitInfo = parseRateLimitError(error);
      
      if (rateLimitInfo.isRateLimit) {
        apiKeyManager.handleRateLimitError('anthropic', apiKey, rateLimitInfo.resetTime, rateLimitInfo.rateLimitType);
        
        const nextKey = apiKeyManager.getAvailableKey('anthropic');
        if (nextKey && nextKey !== apiKey) {
          if (process.env.NODE_ENV !== 'production') {
            console.log(`Anthropic Rate Limit ê°ì§€. ë‹¤ë¥¸ í‚¤ë¡œ ì¬ì‹œë„ ì¤‘... (${retryCount + 1}/3)`);
          }
          return callAnthropic(model, messages, userAttachments, retryCount + 1);
        }
        
        const availability = apiKeyManager.getNextAvailableTime('anthropic');
        throw new Error(availability.message || 'Anthropic API ìš”ì²­ í•œë„ë¥¼ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤.');
      }
    }
    
    throw error;
  }

  const data = await response.json();
  return data.content[0].text;
}

// Perplexity API í˜¸ì¶œ (í‚¤ ë¡œí…Œì´ì…˜ ì§€ì›)
async function callPerplexity(model: string, messages: any[], userAttachments?: UserAttachment[], retryCount: number = 0): Promise<string> {
  const apiKey = apiKeyManager.getAvailableKey('perplexity');
  
  if (!apiKey) {
    throw new Error('Perplexity API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.');
  }

  const modelMap: { [key: string]: string } = {
    'sonar': process.env.SONAR_MODEL || 'sonar',
    'sonarPro': process.env.SONAR_PRO_MODEL || 'sonar-pro',
    'deepResearch': process.env.DEEP_RESEARCH_MODEL || 'sonar-reasoning',
    // ë ˆê±°ì‹œ ë§¤í•‘
    'perplexity-sonar': process.env.PERPLEXITY_SONAR_MODEL || 'sonar',
    'perplexity-sonar-pro': process.env.PERPLEXITY_SONAR_PRO_MODEL || 'sonar-pro',
    'perplexity-deep-research': process.env.PERPLEXITY_DEEP_RESEARCH_MODEL || 'sonar-reasoning'
  };

  const response = await fetch('https://api.perplexity.ai/chat/completions', {
    method: 'POST',
    headers: {
      'Content-Type': 'application/json',
      'Authorization': `Bearer ${apiKey}`
    },
    body: JSON.stringify({
      model: modelMap[model] || 'sonar',
      // PerplexityëŠ” í˜„ì¬ ì´ë¯¸ì§€ ì—…ë¡œë“œ ë¯¸ì§€ì›. ì²¨ë¶€ê°€ ìˆìœ¼ë©´ ì•ˆë‚´ ë¬¸êµ¬ë¥¼ ë³¸ë¬¸ì— ë§ë¶™ì„
      messages: (() => {
        if (!userAttachments?.length) return messages;
        const msgs = [...messages];
        const lastIdx = [...msgs].reverse().findIndex((m: any) => m.role === 'user');
        if (lastIdx === -1) return messages;
        const idx = msgs.length - 1 - lastIdx;
        const last = msgs[idx];
        const note = `\n\n[ì²¨ë¶€ ${userAttachments.length}ê°œëŠ” ì´ ëª¨ë¸ì—ì„œ ì§ì ‘ ì²˜ë¦¬ë˜ì§€ ì•Šì•„ ì œì™¸ë˜ì—ˆìŠµë‹ˆë‹¤.]`;
        msgs[idx] = { ...last, content: `${last.content || ''}${note}` };
        return msgs;
      })()
    })
  });

  if (!response.ok) {
    const errorData = await response.json();
    const error: any = new Error(errorData.error?.message || 'Perplexity API ì˜¤ë¥˜');
    error.status = response.status;
    error.response = { status: response.status, headers: response.headers };
    
    // 429 ì—ëŸ¬ ì²˜ë¦¬
    if (response.status === 429 && retryCount < 3) {
      const rateLimitInfo = parseRateLimitError(error);
      
      if (rateLimitInfo.isRateLimit) {
        apiKeyManager.handleRateLimitError('perplexity', apiKey, rateLimitInfo.resetTime, rateLimitInfo.rateLimitType);
        
        const nextKey = apiKeyManager.getAvailableKey('perplexity');
        if (nextKey && nextKey !== apiKey) {
          if (process.env.NODE_ENV !== 'production') {
            console.log(`Perplexity Rate Limit ê°ì§€. ë‹¤ë¥¸ í‚¤ë¡œ ì¬ì‹œë„ ì¤‘... (${retryCount + 1}/3)`);
          }
          return callPerplexity(model, messages, userAttachments, retryCount + 1);
        }
        
        const availability = apiKeyManager.getNextAvailableTime('perplexity');
        throw new Error(availability.message || 'Perplexity API ìš”ì²­ í•œë„ë¥¼ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤.');
      }
    }
    
    throw error;
  }

  const data = await response.json();
  return data.choices[0].message.content;
}

export async function POST(request: NextRequest) {
  try {
    // Rate Limiting ì²´í¬
    const clientIp = getClientIp(request);
    const rateLimitResult = chatRateLimiter.check(clientIp);

    if (!rateLimitResult.success) {
      return NextResponse.json(
        { 
          error: 'ìš”ì²­ í•œë„ë¥¼ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.',
          retryAfter: Math.ceil((rateLimitResult.reset - Date.now()) / 1000)
        },
        { 
          status: 429,
          headers: {
            'X-RateLimit-Limit': rateLimitResult.limit.toString(),
            'X-RateLimit-Remaining': rateLimitResult.remaining.toString(),
            'X-RateLimit-Reset': new Date(rateLimitResult.reset).toISOString(),
            'Retry-After': Math.ceil((rateLimitResult.reset - Date.now()) / 1000).toString()
          }
        }
      );
    }

    const { modelId, messages, userAttachments, persona } = await request.json();

    // ì…ë ¥ ê²€ì¦
    if (!modelId || !messages || !Array.isArray(messages)) {
      return NextResponse.json(
        { error: 'ì˜ëª»ëœ ìš”ì²­ì…ë‹ˆë‹¤.' },
        { status: 400 }
      );
    }

    // ë©”ì‹œì§€ ê¸¸ì´ ì œí•œ (DoS ë°©ì§€)
    if (messages.length > 100) {
      return NextResponse.json(
        { error: 'ë©”ì‹œì§€ ê°œìˆ˜ê°€ ë„ˆë¬´ ë§ìŠµë‹ˆë‹¤.' },
        { status: 400 }
      );
    }

    // ê° ë©”ì‹œì§€ ë‚´ìš© ê¸¸ì´ ì œí•œ
    for (const msg of messages) {
      if (typeof msg.content === 'string' && msg.content.length > 50000) {
        return NextResponse.json(
          { error: 'ë©”ì‹œì§€ ë‚´ìš©ì´ ë„ˆë¬´ ê¹ë‹ˆë‹¤.' },
          { status: 400 }
        );
      }
    }

    // ì²¨ë¶€íŒŒì¼ í¬ê¸° ì œí•œ
    if (userAttachments && Array.isArray(userAttachments)) {
      if (userAttachments.length > 10) {
        return NextResponse.json(
          { error: 'ì²¨ë¶€íŒŒì¼ ê°œìˆ˜ê°€ ë„ˆë¬´ ë§ìŠµë‹ˆë‹¤.' },
          { status: 400 }
        );
      }
      
      for (const attachment of userAttachments) {
        if (attachment.dataUrl && attachment.dataUrl.length > 10 * 1024 * 1024) {
          return NextResponse.json(
            { error: 'ì²¨ë¶€íŒŒì¼ í¬ê¸°ê°€ ë„ˆë¬´ í½ë‹ˆë‹¤. (ìµœëŒ€ 10MB)' },
            { status: 400 }
          );
        }
      }
    }

    if (process.env.NODE_ENV !== 'production') {
      console.log(`[Chat API] Processing request for model: ${modelId}`);
      console.log(`[Chat API] Messages count: ${messages.length}`);
    }

    // ëª¨ë¸ ì‹œë¦¬ì¦ˆë³„ë¡œ API í˜¸ì¶œ - OpenAIëŠ” ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ë°˜í™˜
    if (modelId.startsWith('gpt') || modelId === 'codex' || modelId.endsWith('codex') || modelId === 'gptimage1') {
      if (process.env.NODE_ENV !== 'production') {
        console.log(`[Chat API] Calling OpenAI API (Streaming)${modelId === 'gptimage1' ? ' (DALL-E)' : ''}`);
      }
      const streamResponse = await callOpenAIStreaming(modelId, messages, userAttachments, persona);
      return streamResponse;
    }
    
    // ë‚˜ë¨¸ì§€ ëª¨ë¸ë“¤ì€ ê¸°ì¡´ ë°©ì‹ ìœ ì§€
    let response: string;
    
    if (modelId.startsWith('gemini')) {
      if (process.env.NODE_ENV !== 'production') {
        console.log('[Chat API] Calling Gemini API');
      }
      response = await callGemini(modelId, messages, userAttachments);
    } else if (modelId.startsWith('claude')) {
      if (process.env.NODE_ENV !== 'production') {
        console.log('[Chat API] Calling Anthropic API');
      }
      response = await callAnthropic(modelId, messages, userAttachments);
    } else if (modelId.startsWith('perplexity')) {
      if (process.env.NODE_ENV !== 'production') {
        console.log('[Chat API] Calling Perplexity API');
      }
      response = await callPerplexity(modelId, messages, userAttachments);
    } else {
      if (process.env.NODE_ENV !== 'production') {
        console.log('[Chat API] Unknown model, using demo response');
      }
      // API í‚¤ê°€ ì—†ìœ¼ë©´ ë°ëª¨ ì‘ë‹µ
      response = `[${modelId}] ì•ˆë…•í•˜ì„¸ìš”! ì§ˆë¬¸ì— ë‹µë³€ë“œë¦¬ê² ìŠµë‹ˆë‹¤. (API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•„ ë°ëª¨ ëª¨ë“œë¡œ ì‹¤í–‰ ì¤‘ì…ë‹ˆë‹¤. .env.local íŒŒì¼ì— API í‚¤ë¥¼ ì¶”ê°€í•˜ì„¸ìš”.)`;
    }

    if (process.env.NODE_ENV !== 'production') {
      console.log(`[Chat API] Response length: ${response?.length || 0} characters`);
    }

    return NextResponse.json(
      { content: response },
      {
        headers: {
          'X-RateLimit-Limit': rateLimitResult.limit.toString(),
          'X-RateLimit-Remaining': rateLimitResult.remaining.toString(),
          'X-RateLimit-Reset': new Date(rateLimitResult.reset).toISOString()
        }
      }
    );

  } catch (error: any) {
    if (process.env.NODE_ENV !== 'production') {
      console.error('Chat API Error:', error);
      console.error('Error stack:', error.stack);
    }
    
    // API í‚¤ê°€ ì—†ëŠ” ê²½ìš° ë°ëª¨ ì‘ë‹µ
    if (error.message.includes('API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤')) {
      return NextResponse.json({ 
        content: `ğŸ’¡ ë°ëª¨ ëª¨ë“œ: ì‹¤ì œ AI ì‘ë‹µì„ ë°›ìœ¼ë ¤ë©´ .env.local íŒŒì¼ì— API í‚¤ë¥¼ ì¶”ê°€í•˜ì„¸ìš”.\n\n` +
                 `ì„¤ì • ë°©ë²•:\n` +
                 `1. í”„ë¡œì íŠ¸ ë£¨íŠ¸ì— .env.local íŒŒì¼ ìƒì„±\n` +
                 `2. ë‹¤ìŒ í™˜ê²½ë³€ìˆ˜ ì¶”ê°€:\n` +
                 `   - OPENAI_API_KEY=your_key (GPT ëª¨ë¸ìš©)\n` +
                 `   - ANTHROPIC_API_KEY=your_key (Claude ëª¨ë¸ìš©)\n` +
                 `   - PERPLEXITY_API_KEY=your_key (Perplexity ëª¨ë¸ìš©)\n\n` +
                 `ìì„¸í•œ ë‚´ìš©ì€ env.example íŒŒì¼ì„ ì°¸ê³ í•˜ì„¸ìš”.`
      });
    }

    // ë¹ˆ ì‘ë‹µ ì—ëŸ¬ì¸ ê²½ìš° ë” ìì„¸í•œ ì •ë³´ ì œê³µ
    const errorMessage = error.message || 'ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.';
    if (process.env.NODE_ENV !== 'production') {
      console.error(`[Chat API] Returning error to client: ${errorMessage}`);
    }
    
    return NextResponse.json(
      { error: errorMessage },
      { status: 500 }
    );
  }
}

